{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "from torch.utils import data\n",
    "import math\n",
    "from datasets.datasets import RobotNavDataset\n",
    "from utils.logging import setup_logger\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now just generate some random data, don't have access to kaggle at work\n",
    "CLASSES = ['fine_concrete', 'concrete', 'soft_tiles', 'tiled', 'soft_pvc',\n",
    "           'hard_tiles_large_space', 'carpet', 'hard_tiles', 'wood']\n",
    "\n",
    "train_set = RobotNavDataset('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowCNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 sequence_length=128,\n",
    "                 n_channels=20,\n",
    "                 conv1_width = 10,\n",
    "                 max_pool_kernel_size=25,\n",
    "                 max_pool_stride=5):\n",
    "        '''\n",
    "        sequence_length: number of measurements in each sequennce\n",
    "        n_channles: number of channels for convolution layers\n",
    "        max_pool_kernel_size: size along 2nd axis (not sure on this wording)\n",
    "        max_pool_stride: stride along 2nd axis\n",
    "        '''\n",
    "        super(ShallowCNN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=(1,conv1_width))\n",
    "        self.conv2 = nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=(10,1))\n",
    "        self.post_conv_width = math.floor(1 + (sequence_length - conv1_width)/self.conv1.stride[1])\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm2d(n_channels)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(1, max_pool_kernel_size), stride=(1, max_pool_stride))\n",
    "        max_pool_w_out = math.floor(1 + (self.post_conv_width - max_pool_kernel_size)/max_pool_stride)\n",
    "        \n",
    "        self.linear = nn.Linear(in_features=n_channels*max_pool_w_out, out_features=9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x = F.dropout2d(x, p=0.5)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.dropout2d(x, p=0.3, training=self.training)\n",
    "        x = F.elu(self.conv2_bn(x))\n",
    "        #x = F.relu(self.conv2_bn(x))\n",
    "        \n",
    "        x = x.view((-1, self.n_channels, self.post_conv_width))\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = x.view((x.size(0), -1))\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ShallowCNN(nn.Module):\\n    def __init__(self, n_conv_channels=40, \\n                 n_signal_channels=10, \\n                 pool_size=25, \\n                 pool_stride=15,\\n                 n_out=10):\\n        \\n        super(ShallowCNN, self).__init__()\\n        \\n        self.conv1 = nn.Conv2d(in_channels=1, \\n                               out_channels=n_conv_channels, \\n                               kernel_size=(1,n_signal_channels))\\n        \\n        self.conv2 = nn.Conv2d(in_channels=n_conv_channels, \\n                               out_channels=n_conv_channels, \\n                               kernel_size=(n_signal_channels,1))\\n        \\n        self.conv2_bn = nn.BatchNorm2d(n_signal_channels)\\n        \\n        self.max_pool = nn.MaxPool2d(kernel_size=(1,pool_size), stride=(1,pool_stride))\\n        # Need to determine how to calculate 7\\n        self.linear = nn.Linear(in_features=40*7, out_features=n_out)\\n        \\n    def forward(self, x):\\n        x = self.conv1(x)\\n        x = self.conv2(x)\\n        x = F.elu(self.conv2_bn(x))\\n        # need to determine how to calculate this size\\n        x = x.view((-1,40,119))\\n        x = self.max_pool(x)\\n        x = x.view((x.size(0), -1))\\n        x = self.linear(x)\\n        return x\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class ShallowCNN(nn.Module):\n",
    "    def __init__(self, n_conv_channels=40, \n",
    "                 n_signal_channels=10, \n",
    "                 pool_size=25, \n",
    "                 pool_stride=15,\n",
    "                 n_out=10):\n",
    "        \n",
    "        super(ShallowCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, \n",
    "                               out_channels=n_conv_channels, \n",
    "                               kernel_size=(1,n_signal_channels))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=n_conv_channels, \n",
    "                               out_channels=n_conv_channels, \n",
    "                               kernel_size=(n_signal_channels,1))\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm2d(n_signal_channels)\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(1,pool_size), stride=(1,pool_stride))\n",
    "        # Need to determine how to calculate 7\n",
    "        self.linear = nn.Linear(in_features=40*7, out_features=n_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.elu(self.conv2_bn(x))\n",
    "        # need to determine how to calculate this size\n",
    "        x = x.view((-1,40,119))\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((x.size(0), -1))\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShallowCNN(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(1, 10), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(10, 1), stride=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (max_pool): MaxPool2d(kernel_size=(1, 25), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear): Linear(in_features=380, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ShallowCNN()\n",
    "#model.double()\n",
    "model.to('cpu')\n",
    "# foo.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 20, 10, 119]             220\n",
      "            Conv2d-2           [-1, 20, 1, 119]           4,020\n",
      "       BatchNorm2d-3           [-1, 20, 1, 119]              40\n",
      "         MaxPool2d-4               [-1, 20, 19]               0\n",
      "            Linear-5                    [-1, 9]           3,429\n",
      "================================================================\n",
      "Total params: 7,709\n",
      "Trainable params: 7,709\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.22\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=train_set.train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = floor(0.8*len(train_set))\n",
    "test_size = floor(0.2*len(train_set))\n",
    "\n",
    "train_subset, test_subset = data.random_split(train_set, (train_size, test_size))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_subset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# Don't think we actually need shuffle here...\n",
    "test_loader = torch.utils.data.DataLoader(test_subset,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training import train, test\n",
    "logger = setup_logger(logfile='foo.log', console_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\tLoss: 2.385076\n",
      "Train Epoch: 1\tLoss: 2.385076\n",
      "Train Epoch: 1\tLoss: 2.006884\n",
      "Train Epoch: 1\tLoss: 2.006884\n",
      "\n",
      "Test set: Average loss: 1.9891, Accuracy: 153/762 (20%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.9891, Accuracy: 153/762 (20%)\n",
      "\n",
      "Train Epoch: 2\tLoss: 1.986988\n",
      "Train Epoch: 2\tLoss: 1.986988\n",
      "Train Epoch: 2\tLoss: 1.984002\n",
      "Train Epoch: 2\tLoss: 1.984002\n",
      "\n",
      "Test set: Average loss: 1.9239, Accuracy: 185/762 (24%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.9239, Accuracy: 185/762 (24%)\n",
      "\n",
      "Train Epoch: 3\tLoss: 1.931040\n",
      "Train Epoch: 3\tLoss: 1.931040\n",
      "Train Epoch: 3\tLoss: 1.913984\n",
      "Train Epoch: 3\tLoss: 1.913984\n",
      "\n",
      "Test set: Average loss: 1.8318, Accuracy: 223/762 (29%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.8318, Accuracy: 223/762 (29%)\n",
      "\n",
      "Train Epoch: 4\tLoss: 1.748256\n",
      "Train Epoch: 4\tLoss: 1.748256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b5fb4dd95bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle-robot-navigation/utils/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, loss_func, epoch, device, log_interval, log_func)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mpatience\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHow\u001b[0m \u001b[0mlong\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwait\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mimproved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                             \u001b[0mDefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprints\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mimprovement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                             \u001b[0mDefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-27e489f56322>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#x = F.dropout2d(x, p=0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "log_interval = 40\n",
    "model.double()\n",
    "\n",
    "loss_func = F.nll_loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train(model, train_loader, optimizer, loss_func, epoch, log_interval=log_interval, log_func=logger.info)\n",
    "    test(model, test_loader, loss_func, log_func=logger.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfasd\n",
      "asdfasd\n",
      "asdfasd\n",
      "asdfasd\n"
     ]
    }
   ],
   "source": [
    "logger.info('asdfasd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/3810 (0%)]\tLoss: 1.347208\n",
      "Train Epoch: 2 [0/3810 (0%)]\tLoss: 1.364793\n",
      "Train Epoch: 3 [0/3810 (0%)]\tLoss: 1.187895\n",
      "Train Epoch: 4 [0/3810 (0%)]\tLoss: 1.231539\n",
      "Train Epoch: 5 [0/3810 (0%)]\tLoss: 1.227063\n",
      "Train Epoch: 6 [0/3810 (0%)]\tLoss: 1.244717\n",
      "Train Epoch: 7 [0/3810 (0%)]\tLoss: 1.368650\n",
      "Train Epoch: 8 [0/3810 (0%)]\tLoss: 1.259439\n",
      "Train Epoch: 9 [0/3810 (0%)]\tLoss: 1.581491\n",
      "Train Epoch: 10 [0/3810 (0%)]\tLoss: 1.418440\n",
      "Train Epoch: 11 [0/3810 (0%)]\tLoss: 1.455553\n",
      "Train Epoch: 12 [0/3810 (0%)]\tLoss: 1.388214\n",
      "Train Epoch: 13 [0/3810 (0%)]\tLoss: 1.464187\n",
      "Train Epoch: 14 [0/3810 (0%)]\tLoss: 1.320769\n",
      "Train Epoch: 15 [0/3810 (0%)]\tLoss: 1.313512\n",
      "Train Epoch: 16 [0/3810 (0%)]\tLoss: 1.289399\n",
      "Train Epoch: 17 [0/3810 (0%)]\tLoss: 1.568147\n",
      "Train Epoch: 18 [0/3810 (0%)]\tLoss: 1.457238\n",
      "Train Epoch: 19 [0/3810 (0%)]\tLoss: 1.330974\n",
      "Train Epoch: 20 [0/3810 (0%)]\tLoss: 1.239509\n",
      "Train Epoch: 21 [0/3810 (0%)]\tLoss: 1.078833\n",
      "Train Epoch: 22 [0/3810 (0%)]\tLoss: 1.168862\n",
      "Train Epoch: 23 [0/3810 (0%)]\tLoss: 1.349740\n",
      "Train Epoch: 24 [0/3810 (0%)]\tLoss: 1.382105\n",
      "Train Epoch: 25 [0/3810 (0%)]\tLoss: 1.266839\n",
      "Train Epoch: 26 [0/3810 (0%)]\tLoss: 1.373106\n",
      "Train Epoch: 27 [0/3810 (0%)]\tLoss: 1.068598\n",
      "Train Epoch: 28 [0/3810 (0%)]\tLoss: 1.245773\n",
      "Train Epoch: 29 [0/3810 (0%)]\tLoss: 1.465444\n",
      "Train Epoch: 30 [0/3810 (0%)]\tLoss: 1.429314\n",
      "Train Epoch: 31 [0/3810 (0%)]\tLoss: 1.276763\n",
      "Train Epoch: 32 [0/3810 (0%)]\tLoss: 1.389217\n",
      "Train Epoch: 33 [0/3810 (0%)]\tLoss: 1.280353\n",
      "Train Epoch: 34 [0/3810 (0%)]\tLoss: 1.296143\n",
      "Train Epoch: 35 [0/3810 (0%)]\tLoss: 1.304710\n",
      "Train Epoch: 36 [0/3810 (0%)]\tLoss: 1.464449\n",
      "Train Epoch: 37 [0/3810 (0%)]\tLoss: 1.464824\n",
      "Train Epoch: 38 [0/3810 (0%)]\tLoss: 1.301574\n",
      "Train Epoch: 39 [0/3810 (0%)]\tLoss: 1.402340\n",
      "Train Epoch: 40 [0/3810 (0%)]\tLoss: 1.485366\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "log_interval = 80\n",
    "model.train()\n",
    "model.double()\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1127, Accuracy: 2395/3810 (63%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        #data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(train_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(train_loader.dataset),\n",
    "100. * correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShallowCNN(\n",
       "  (conv1): Conv2d(1, 40, kernel_size=(1, 10), stride=(1, 1))\n",
       "  (conv2): Conv2d(40, 40, kernel_size=(10, 1), stride=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (max_pool): MaxPool2d(kernel_size=(1, 25), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear): Linear(in_features=760, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
